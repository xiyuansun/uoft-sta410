t3 <- mle_mos(130, 25, 25, 75, 20, 6, data3, 50)
for (i in 1:10) {
t2 <- mle_mvn(130, 25, 25, 75, 20, 6, data3, i)
print(abs(opm - t2)/(abs(opm - t2))^(i))
}
for (i in 1:10) {print(i)}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
data3 <- c (0.5777855955529958, 0.49522762512788177)
opm <- c(0.83007546584433389, 0.28329283584105291)
t1 <- mle_alt(130, 25, 25, 75, 20, 6, data3)
t3 <- mle_mos(130, 25, 25, 75, 20, 6, data3, 50)
for (i in 1:10) {
t2 <- mle_mvn(130, 25, 25, 75, 20, 6, data3, i)
tt2 <- mle_mvn(130, 25, 25, 75, 20, 6, data3, i+1)
print(abs(opm - tt2)/(abs(opm - t2))^(i))
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 15))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 15))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 15))
#print(mle_mvn(130, 25, 25, 75, 20, 6, data2, 15))
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
#print(mle_mvn(130, 25, 25, 75, 20, 6, data2, 15))
options(digits=17)
# since we cannot comment out the call of the cat function online, so I used the modified version locally
# source("http://utstat.utoronto.ca/~radford/sta410/bisect.r")
source("~/Dropbox/1516/STA410cstat/codes/week2/bisect.r")
source("http://utstat.utoronto.ca/~radford/sta410/mvnewton.r")
# First we need to implement these helper functions:
log_likelihood <- function (p, n, m1, m2, x, x1, x2) {
p1 <- p[1]
p2 <- p[2]
if(any(p<=0)) {
-Inf
}
if(p1+p2>=2) {
-Inf
}
if(any(p>=1)) {
-Inf
}
else {(log(choose(n, x))+log(choose(m1, x1))+log(choose(m2,x2))
+x*log((p1+p2)/2)+(n-x)*log(1-(p1+p2)/2)
+x1*log(p1)+(m1-x1)*log(1-p1)
+x2*log(p2)+(m2-x2)*log(1-p2))
}
}
log_likelihood_gradient <- function (p, n ,m1, m2, x, x1, x2) {
p1 <- p[1]
p2 <- p[2]
dp1 <- x/(p1+p2)+(n-x)/(p1+p2 - 2)+x1/p1+(m1-x1)/(p1-1)
dp2 <- x/(p1+p2)+(n-x)/(p1+p2 - 2)+x2/p2+(m2-x2)/(p2-1)
c (dp1, dp2)
}
log_likelihood_hessian <- function (p, n, m1, m2, x, x1, x2) {
p1 <- p[1]
p2 <- p[2]
matrix (c (-x*(p1+p2)^(-2)-(n-x)*(p1+p2-2)^(-2)-x1*p1^(-2)-(m1-x1)*(p1-1)^(-2),
-x*(p1+p2)^(-2)-(n-x)*(p1+p2-2)^(-2),
-x*(p1+p2)^(-2)-(n-x)*(p1+p2-2)^(-2),
-x*(p1+p2)^(-2)-(n-x)*(p1+p2-2)^(-2)-x2*p2^(-2)-(m2-x2)*(p2-1)^(-2)),
2, 2)
}
fisher_information <- function (p, n, m1, m2, x, x1, x2) {
p1 <- p[1]
p2 <- p[2]
matrix (c (n/2*(p1+p2)^(-1)+n/2*(2-p1-p2)^(-1)+m1/p1+m1*(1-p1)^(-1), n/2*(p1+p2)^(-1)+n/2*(2-p1-p2)^(-1),
n/2*(p1+p2)^(-1)+n/2*(2-p1-p2)^(-1), n/2*(p1+p2)^(-1)+n/2*(2-p1-p2)^(-1)+m2/p2+m2*(1-p2)^(-1)),
2, 2)
# why do i need to have minus here???? maybe?
}
# Method 1: Alternating maximization (non-linear Gauss-Siedel iteration)
mle_alt <- function (n, m1, m2, x, x1, x2, initial) {
origin <- initial
temp <- c (2, 2) # impossible values by definition
i <- 1 # iteration counter
while (origin[1] != temp[1] || origin[2] != temp[2]) {
if (i != 1) {
origin <- temp
}
# to iterative alternatively, we need to fix one parameter at a time
# fixed p2
f <- function(p) {
x/(p+origin[2])+(n-x)/(p+origin[2]-2)+x1/p+(m1-x1)/(p-1)
}
# fixed p1
g <- function(p) {
x/(origin[1]+p)+(n-x)/(origin[1]+p - 2)+x2/p+(m2-x2)/(p-1)
}
temp <- c(bisect2(f, 0.001, 0.999), bisect2(g, 0.001, 0.999))
cat("i =", i, "p1 =", temp[1], "p2 =", temp[2], "\n")
i <- i+1
}
}
# Method 2: Multivariate Newton iteration
mle_mvn <- function (n, m1, m2, x, x1, x2, initial, iters) {
mvnewton (function (p) log_likelihood_gradient(p, n, m1, m2, x, x1, x2),
function (p) log_likelihood_hessian(p, n, m1, m2, x, x1, x2) , initial, iters)
}
# Method 3: Multivariate method of scoring
mle_mos <- function (n, m1, m2, x, x1, x2, initial, iters) {
mvnewton (function (p) log_likelihood_gradient(p, n, m1, m2, x, x1, x2),
function (p) -fisher_information(p, n, m1, m2, x, x1, x2), initial, iters)
# either add a minus here or add a minus in fisher_information()
}
# Method 4: Râ€™s built-in nlm function
mle_nlm <- function (n,m1,m2,x,x1,x2,initial) {
nlm(function (p) -log_likelihood(p, n, m1, m2, x, x1, x2), initial, hessian=TRUE)
}
mle_alt(130,25,25,75,20,6,c(0.5,0.5))
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
# find convergence order
optimizer <- c(0.83007546584433389, 0.28329283584105291)
for (i in 1:10) {
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1)))^(1))
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1)))^(2))
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
# find convergence order
optimizer <- c(0.83007546584433389, 0.28329283584105291)
for (i in 1:10) {
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))^(1))
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))^(2))
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
# find convergence order
optimizer <- c(0.83007546584433389, 0.28329283584105291)
for (i in 1:10) {
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(1))
print((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(2))
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
# find convergence order
optimizer <- c(0.83007546584433389, 0.28329283584105291)
for (i in 1:10) {
cat((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(1))
cat((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(2))
}
source("~/Dropbox/1516/STA410cstat/A1/function.r")
options(digits=17)
n <- 130
m1 <- 25
m2 <- 25
x <- 75
x1 <- 20
x2 <- 6
iters <- 10
initial <- c (0, 0)
i <- 1
while (i < 4) {
set.seed(i)
initial[1] <- runif(1, 0.5, 1) # we tend to set our initial guess suitable, as the observed p1 = 0.8
initial[2] <- runif(1, 0, 0.5) # similarly since observed p2 = 0.24
cat("\nAlternating Maximization with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( a <- mle_alt(n, m1, m2, x, x1, x2, initial))
cat("\nMultivariate Newton Iteration with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( b <- mle_mvn(n, m1, m2, x, x1, x2, initial, iters))
cat("\nMultivariate Method of Scoring with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( c <- mle_mos(n, m1, m2, x, x1, x2, initial, iters))
cat("\nBuilt-in nlm Function with initial guess p1 =", initial[1], "and p2=", initial[2], "\n")
print( d <- mle_nlm(n, m1, m2, x, x1, x2, initial))
i <- i + 1
}
# increase times of iterations for mvn and mos
# these are results of previous random number generation.
data1 <- c (0.63275433157104999, 0.18606194981839508)
data2 <- c (0.59244112996384501, 0.35118701797910035)
data3 <- c (0.58402076316997409, 0.40375819953624159)
print(mle_mos(130, 25, 25, 75, 20, 6, data1, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data2, 20))
print(mle_mos(130, 25, 25, 75, 20, 6, data3, 20))
# find convergence order
optimizer <- c(0.83007546584433389, 0.28329283584105291)
for (i in 1:10) {
((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(1))[1]
((abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i+1) - optimizer))/(abs(mle_mvn(130, 25, 25, 75, 20, 6, data1, i) - optimizer))^(2))[1]
}
mle_mvn(130, 25, 25, 75, 20, 6, data1, 10)[1]
cat(mle_mvn(130, 25, 25, 75, 20, 6, data1,10)[1])
mle_mvn(130, 25, 25, 75, 20, 6, data1,10)[1]$10
mle_mvn(130, 25, 25, 75, 20, 6, data1,10)[1]$iteration10
mle_mvn(130, 25, 25, 75, 20, 6, data1,10)[1]?
help
x + y = 3
x + y <- 3
3 <- x + y
y <- 3 - x
y <- 2x
y <- 2 * x
x
y
p <- c(0.83007546584433389, 0.28329283584105291)
p44 <- c(0.83007546584433345, 0.28329283584105319)
p45 <- c(0.83007546584433378, 0.28329283584105319)
epsilon44 <- p - p44
epsilon45 <- p - p45
c <- (abs(epsilon44[1]))^(beta) / abs(epsilon45[1])
y <- 2 * x
y <- 3 - x
x
y
haha <- 2 * x
hoho <- 3 - x
haha
haha <- 2 * abcd
epsilon44 <- p - p44
epsilon44
epsilon45
p40 <- c(0.83007546584432346, 0.28329283584105758)
p41 <- c(0.83007546584433212, 0.28329283584105858)
epsilon40 <- p - p40
epsilon40
epsilon41 <- p - p41
epsilon41
log2(3)
log2(3)^3
log2
log2(3)^(3)
test <- log2(3)
test^(3)
log2(4)
log(2)(4)
log(2,4)
log2(4)
log3/2
log3/2(1.5)
5.6/1.776
log3.153153(4.6/10.4)
log3(4.6/10.4)
log(5.6/1.776, base = 4.6/10.4)
log(4.6/10.4, base = 5.6/1.776)
p <- c(0.83007546584433389, 0.28329283584105291)
p4 <- c(0.8154026622995294, 0.28985591106798514)
p5 <- c(0.82748064472964256, 0.29124514546598468)
epsilon4 <- p - p4
epsilon5 <- p - p5
epsilon4
epsilon5
147/65
26/80
log(2.26, base = 0.325)
epsilon6 <- p - p6
p6 <- c(0.82692604895733246, 0.28469206484253617)
epsilon6 <- p - p6
epsilon6
epsilon5[1] * epsilon6[1]
epsilon5[1] / epsilon6[1]
epsilon4[1] / epsilon5[1]
log(0.8239053, base = 5.654649)
log(epsilon5[2] / epsilon6[2], base = epsilon4[2] / epsilon5[2])
log(epsilon4[2] / epsilon5[2], base = epsilon5[2] / epsilon6[2])
> log(epsilon4[2] / epsilon5[2], base = epsilon5[2] / epsilon6[2])
> log(epsilon4[2] / epsilon5[2], base = epsilon5[2] / epsilon6[2])
log(epsilon4[2] / epsilon5[2], base = epsilon5[2] / epsilon6[2])
log(epsilon4[1] / epsilon5[1], base = epsilon5[1] / epsilon6[1])
log(abs(epsilon5[1] / epsilon6[1]), base = abs(epsilon4[1] / epsilon5[1]))
log(abs(epsilon5[2] / epsilon6[2]), base = abs(epsilon4[2] / epsilon5[2]))
p <- c(0.83007546584433389, 0.28329283584105291)
p44 <- c(0.83007546584433345, 0.28329283584105319)
p45 <- c(0.83007546584433378, 0.28329283584105319)
p46 <- c(0.83007546584433378, 0.83007546584433378)
epsilon44 <- p - p44
epsilon45 <- p - p45
epsilon46 <- p - p46
epsilon444
epsilon44
epsilon45
epsilon46
epsilon46
p46 <- c(0.83007546584433378, 0.28329283584105291)
epsilon46 <- p - p46
epsilon46
p - p43
p43 <- c(0.83007546584433345, 0.28329283584105414)
epsilon43 <- p - p43
epsilon43
print(solve(-fisher_information(p_mle, n, m1, m2, x, x1, x2))[1][1]^2)
p <- c(0.83007546584433389, 0.28329283584105291)
p4 <- c(0.83046607572012954, 0.28305307635107246)
p5 <- c(0.8300760651000777, 0.2832924650233955)
p6 <- c(0.83007546584574299, 0.28329283584017867)
epsilon4 <- p - p4
epsilon5 <- p - p5
epsilon6 <- p - p6
epsilon4
epsilon5
epsilon6
p <- c(0.83007546584433389, 0.28329283584105291)
p4 <- c(0.83017312892992112, 0.28326036220547818)
p5 <- c(0.83006630050474739, 0.28329643543771804)
p6 <- c(0.83007631357123401, 0.28329253172802304)
epsilon4 <- p - p4 # -0.0003906099  0.0002397595
epsilon5 <- p - p5 # -5.992557e-07  3.708177e-07
epsilon6 <- p - p6 # -1.409095e-12  8.742451e-13
epsilon4
epsilon5
epsilon6
